+++
title = "Histogram of Oriented Gradients"
authors = ["Alex Dillhoff"]
date = 2022-01-22T00:00:00-06:00
tags = ["computer vision"]
draft = false
lastmod = 2024-01-28
+++

<div class="ox-hugo-toc toc">

<div class="heading">Table of Contents</div>

- [Introduction](#introduction)
- [Orientation Histograms](#orientation-histograms)
- [Histogram of Oriented Gradients](#histogram-of-oriented-gradients)

</div>
<!--endtoc-->



## Introduction {#introduction}

**Key Questions**

-   Why are these necessary?
-   What limitations do they address that corner interest points cannot?

Although the original [HOG Paper](http://vision.stanford.edu/teaching/cs231b_spring1213/papers/CVPR05_DalalTriggs.pdf) came out after [SIFT](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf), it is much simpler to describe the process.
Histograms of Oriented Gradients are feature vectors that are generated by evaluating gradients within a local neighborhood of interest points.


## Orientation Histograms {#orientation-histograms}

This approach depends on building [orientation histograms](https://john.cs.olemiss.edu/heroes/papers/hand_gesture.pdf).
For each pixel in the original image, construct a histogram of gradient orientations of all pixels within a square window.
The gradient orientations of each pixel are easily calculated following the approach used for [Edge Detection]({{< relref "edge_detection.md" >}}).
This transformation can be flattened into a single vector that is used to compare images via L2 distance or some other metric.

{{< figure src="/ox-hugo/2022-02-12_19-48-07_screenshot.png" caption="<span class=\"figure-number\">Figure 1: </span>Orientation histograms of hand images." >}}

The pseudocode to generate orientation histograms is shown below.

```nil
let w be the window_size
let h be half the window_size
let norms be the gradient norms of the input image for each pixel
let angles be the computed orientations of the gradient vectors for each pixel
for each pixel (i, j):
    create a histogram of orientations with $b$ bins
    weight the orientations of the bins based on the gradient norm
```

The histograms of each local feature are translation invariant.
A histogram of gradient orientations for a feature in one image should be the same as one generated to a similar feature in another image.

This approach is not scale invariant.


## Histogram of Oriented Gradients {#histogram-of-oriented-gradients}

Dalal and Triggs (2005) propose a feature extraction method based on orientatio histograms.
In their work published at CVPR, they evaluate their features by training a SVM for pedestrian detection on a standard (at that time) benchmark.
They evaluate on a person detector using the metric **False Positives Per Window (FPPW)**.
This can be calculated as \`num_fp / num_windows\`.


### Computing HoG {#computing-hog}

1.  Extract a window of some size.
2.  Divide window into sub-grid
3.  Compute orientation histogram of each cell.
4.  Concatentate the four histograms.
5.  Normalize the feature vector.

Usually choose 4 cells per window with 9 orientation bins.


### Normalization Schemes {#normalization-schemes}

There were several normalizion schemes addressed in the paper.
The normalization scheme picked based on lowest FPPW is \`L2-Hys\`:

1.  Normalize the concatenated vector.
2.  Clip values to 0.2
3.  Normalize again.

They also evaulated the features with L2, L1, and L1-sqrt.

{{< figure src="/ox-hugo/2022-02-12_15-48-55_screenshot.png" caption="<span class=\"figure-number\">Figure 2: </span>Evaluation of normalization approaches (Dalal and Triggs, 2005)." >}}
